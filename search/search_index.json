{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>This is the manual of krangl.</p> <p><code>krangl</code> is an open-source {K}otlin library for data w{rangl}ing. By implementing a grammar of data manipulation using a modern functional-style API, it allows to filter, transform, aggregate and reshape tabular data.</p> <p><code>krangl</code> tries to become what pandas is for <code>python</code>, and <code>readr</code>+<code>tidyr</code>+<code>dplyr</code> are for R.</p> <p><code>krangl</code> is open-source and developed on github.</p> <p>For a first primer see KotlinConf 2019 slides about Data Science with kotlin</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Filter, transform, aggregate and reshape tabular data</li> <li>Modern, user-friendly and easy-to-learn data-science API</li> <li>Reads from plain and compressed tsv, csv, json, or any delimited format with or without header from local or remote</li> <li>Supports grouped operations</li> <li>Ships with JDBC support</li> <li>Tables can contain atomic columns (int, double, boolean) as well as object columns</li> <li>Reshape tables from wide to long and back</li> <li>Table joins (left, right, semi, inner, outer)</li> <li>Cross tabulation</li> <li>Descriptive statistics (mean, min, max, median, ...)</li> <li>Functional API inspired by dplyr, pandas, and Kotlin stdlib</li> </ul> <p>Furthermore, it provides methods to go back and forth between untyped and typed data.</p>"},{"location":"#installation","title":"Installation","text":"<p>To get started simply add it as a dependency: <pre><code>repositories {\nmavenCentral()\n}\n\ndependencies {\nimplementation \"com.github.holgerbrandl:krangl:0.18.4\"\n}\n</code></pre> Declaring the repository is purely optional as it is the default already.</p> <p>If you're very new to Kotlin and Gradle you may want to read first about its basic syntax, some basic IDE features and about how to use gradle to configure dependencies in Kotlin projects.</p>"},{"location":"#example","title":"Example","text":"<p>Flights that departed NYC, are grouped by date, some columns of interest are selected, dasummarized to reveal mean departure and arrival delays, and finally just those dates are kept that show extreme delays.</p> <pre><code>flights\n.groupBy(\"year\", \"month\", \"day\")\n.select({ range(\"year\", \"day\") }, { listOf(\"arr_delay\", \"dep_delay\") })\n.summarize(\n\"mean_arr_delay\" to { it[\"arr_delay\"].mean(removeNA = true) },\n\"mean_dep_delay\" to { it[\"dep_delay\"].mean(removeNA = true) }\n)\n.filter { (it[\"mean_arr_delay\"] gt  30)  OR  (it[\"mean_dep_delay\"] gt  30) }\n</code></pre>"},{"location":"10_minutes/","title":"<code>krangl</code> in 3 Minutes","text":"<p>Welcome to <code>krangl</code>. Relational data and how to handle it properly is a huge topic, but the core concepts are relatively simple. So let's get started!</p>"},{"location":"10_minutes/#columns-and-rows","title":"Columns and Rows","text":"<p>DataFrames are just tables with type constraints within each column. To glance into them horizontally and vertically we can do</p> <pre><code>irisData.print(maxRows=10)\nirisData.schema()\n</code></pre> <p><code>irisData</code> is bundled with krangl, and  gives the measurements in centimeters of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris. The species are Iris setosa, versicolor, and virginica.</p> <p></p> <p>Columns and Rows can be accessed using <code>krangl</code> with</p> <pre><code>val col = irisData[\"Species\"]\nval cell = irisData[\"Species\"][1]\n</code></pre>"},{"location":"10_minutes/#get-your-data-into-krangl","title":"Get your data into <code>krangl</code>","text":"<p>To save a data frame simply use</p> <pre><code>irisData.writeCSV(File(\"my_iris.txt\"))\n</code></pre> <p>To load a data-frame simply {done}</p> <pre><code>irisData.writeCSV(File(\"my_iris.txt\"))\n</code></pre> <p>It allows to Read from tsv, csv, json, jdbc, e.g.</p> <pre><code>val tornados = DataFrame.readCSV(pathAsStringFileOrUrl)\ntornados.writeCSV(File(\"tornados.txt.gz\"))\n</code></pre> <p><code>krangl</code> will guess column types unless the user provides a column type model.</p> <p>You can also simply define new data-frames in place</p> <pre><code>val users : DataFrame = dataFrameOf(\n\"firstName\", \"lastName\", \"age\", \"hasSudo\")(\n\"max\", \"smith\" , 53, false,\n\"eva\", \"miller\", 23, true,\nnull , \"meyer\" , 23, null\n)\n</code></pre> <p>Note</p> <p><code>krangl</code> also allows to convert any iterable into a data-frame via reflection. See the section about Reshaping Data for details.</p>"},{"location":"10_minutes/#other-input-formats","title":"Other input formats","text":"<p><code>krangl</code> also allows to read in json array data. For a complete overview see JsonIO</p> <pre><code>val df = fromJson(\"my.json\")\nval df2 = fromJson(\"http://foo.bar/my.json\")\n</code></pre>"},{"location":"about/","title":"About","text":""},{"location":"about/#license","title":"License","text":"<p><code>krangl</code> is licensed under MIT License.</p>"},{"location":"about/#acknowledgements","title":"Acknowledgements","text":"<p><code>kalasim</code> started off as a blunt rewrite of dplyr. and we are deeply thankful for its permissive licence that enabled setting up this project.</p>"},{"location":"about/#references","title":"References","text":"<p>Similar APIs (not just Kotlin)</p> <ul> <li>Scala DataTable: a lightweight, in-memory table structure written in Scala</li> <li>joinery implements data frames for Java</li> <li>tablesaw which is (according to its authors) the The simplest way to slice data in Java</li> <li>paleo which provides immutable Java 8 data frames with typed columns</li> <li>agate isa  Python data analysis library that is optimized for humans instead of machines</li> <li>pandas provides high-performance, easy-to-use data structures and data analysis tools for python (cheatsheet)</li> <li>dplyr which is a grammar of data manipulation (R-lang)</li> <li>morpheus-core which is a data science framework implementing an R-like data-frame for the JVM</li> <li>Frameless is a Scala library for working with Spark using more expressive types, including a more strongly typed Dataset/DataFrame API</li> <li>https://dataframes.juliadata.org/stable/ A modern recent addition to the Julia data-science ecosystem</li> </ul> <p>Other data-science projects</p> <ul> <li>vectorz is a fast and flexible numerical library for Java featuring N-dimensional arrays</li> <li>koma is a scientific computing library written in Kotlin, designed to allow development of cross-platform numerical applications</li> <li>termsql converts text from a file or from stdin into SQL table and query it instantly. Uses sqlite as backend.</li> <li>kotliquery is a handy database access library</li> <li>Dex : The Data Explorer is a data visualization tool written capable of powerful ETL and publishing web visualizations</li> </ul> <p>Data Visualization</p> <ul> <li>kravis which implements a Kotlin DSL for scientific data visualization</li> <li>XChart is a light weight Java library for plotting data</li> <li>Charts in TornadoFX provide visualzation examples using javaFX</li> </ul>"},{"location":"about/#repo-maintainer","title":"Repo Maintainer","text":"<p>Holger Brandl holds a Ph.D. degree in machine learning and has developed new concepts in the field of computational linguistics. More recently he has co-authored publications in high-ranking journals such as Nature and Science. To stay in sync with what's happening in tech, he's developing open-source tools, methods and algorithms for bioinformatics, high-performance computing and data science. He's passionate about data science, machine learning, kotlin, R, elegant APIs and data visualisation in particular in relations applications from systems biology and industrial manufacturing.</p>"},{"location":"apidocs/","title":"API Docs","text":"<p>Built with love and dokka, we also provide Krangl API Docs.</p>"},{"location":"data_manip/","title":"Add columns with <code>addColumn</code>","text":"<pre><code>val df: DataFrame = dataFrameOf(\n\"first_name\", \"last_name\", \"age\", \"weight\")(\n\"Max\", \"Doe\", 23, 55,\n\"Franz\", \"Smith\", 23, 88,\n\"Horst\", \"Keanes\", 12, 82)\n\ndf.addColumn(\"salary_category\") { 3 }             // add constants\ndf.addColumn(\"age_3y_later\") { it[\"age\"] + 3 }    // do basic column arithmetics\n\n// krangl dataframes are immutable so we need to (re)assign results to preserve changes.\nval newDF = df.addColumn(\"full_name\") { it[\"first_name\"] + \" \" + it[\"last_name\"] }\n\n// krangl overloads  arithmetic operators like + for dataframe-columns\ndf.addColumn(\"user_id\") { it[\"last_name\"] + \"_id\" + rowNumber }\n\n//and provides convenience methods to ignore NAs\ndf.addColumn(\"first_name_initial\") { it[\"first_name\"].map&lt;String&gt;{ it.first() } }\n\n// or add multiple columns at once\ndf.addColumns(\n\"age_plus3\" to { it[\"age\"] + 3 },\n\"initial\" to { it[\"first_name\"].map&lt;String&gt; { it.first() } }\n)\n</code></pre> <p>To make create columns starting with constant values those need to be expanded to static columns using with <code>const</code> <pre><code>df.createColumn(\"user_id\") { const(\"id\") + nrow }\n</code></pre></p>"},{"location":"data_manip/#get-your-data-in-order-with-sortedby","title":"Get your data in order with <code>sortedBy</code>","text":"<pre><code>df.sortedBy(\"age\")\n\n// and add secondary sorting attributes as varargs\ndf.sortedBy(\"age\", \"weight\")\n\n// reverse sorting order\ndf.sortedByDescending(\"age\")\ndf.sortedBy{ desc(\"age\") }\n\n// sort descending by age, and resolve ties by weight\ndf.sortedBy({ desc(it[\"age\"]) }, { it[\"weight\"] })\n\n\n// sort with indicator lambda\ndf.sortedBy { it[\"weight\"].round() }\n</code></pre> <p>???</p> <p>mimic Kotlin stdlib where possible</p>"},{"location":"data_manip/#subset-variables-with-select","title":"Subset variables with <code>select</code>","text":"<pre><code>// positive selection\ndf.select(\"last_name\", \"weight\")    // negative selection\ndf.remove(\"weight\", \"age\")  // selector mini-language\ndf.select { endsWith(\"name\") }   df.select { matches(\"foo[0-9\") }\n\n// functional style column selection\n// odd name to avoid JVM signature clash (help welcome!)\ndf.select2 { it is IntCol } // rename columns\ndf.rename(\"last_name\" to \"Nachname\")\n</code></pre> <p>{% hint style=\"warning\" %}  Be aware that the usage of string constants as function literals is legit kotlin code <code>sleepData.sortedBy{ \"order\" }</code> but lacks select semantics. <code>krangl</code> will throw an error in such a case. {% endhint %}</p>"},{"location":"data_manip/#subset-your-records-with-filter","title":"Subset your records with <code>filter</code>","text":"<pre><code>// Subset rows with vectorized filter\ndf.filter { it[\"age\"] eq 23 }\ndf.filter { it[\"weight\"] gt 50 }\ndf.filter({ it[\"last_name\"].isMatching { startsWith(\"Do\")  }})\n</code></pre> <p>In case vectorized operations are not possible or available we can also filter tables by row which allows for scalar operators <pre><code>df.filterByRow { it[\"age\"] as Int &gt; 5 }\ndf.filterByRow { (it[\"age\"] as Int).rem(10) == 0 } // \"round\" birthdays :-)\n</code></pre></p>"},{"location":"data_manip/#summarize-your-data-with-summarize","title":"Summarize your data with <code>summarize</code>","text":"<pre><code>// do simple cross tabulations\ndf.count(\"age\", \"last_name\")\n\n// ... or calculate single summary statistic\ndf.summarize(\"mean_age\") { it[\"age\"].mean(true) }\n\n// ... or multiple summary statistics\ndf.summarize(\n\"min_age\" to { it[\"age\"].min() },\n\"max_age\" to { it[\"age\"].max() }\n)\n\n// for sake of r and python transition you can also use `=` here\ndf.summarize(\n\"min_age\" `=` { it[\"age\"].min() },\n\"max_age\" `=` { it[\"age\"].max() }\n)\n</code></pre>"},{"location":"data_manip/#perform-grouped-operations-after-groupby","title":"Perform grouped operations after <code>groupBy</code>","text":"<pre><code>val groupedDf: DataFrame = df.groupBy(\"age\") // ... or provide multiple grouping attributes with varargs\n\nval sumDF = groupedDf.summarize(\n\"mean_weight\" to { it[\"weight\"].mean(removeNA = true) },\n\"num_persons\" to { nrow }\n)\n\n// Optionally ungroup the data\nsumDF.ungroup()\n</code></pre>"},{"location":"data_manip/#bring-it-all-together","title":"Bring it all together","text":"<pre><code>flightsData\n.groupBy(\"year\", \"month\", \"day\")\n.select({ range(\"year\", \"day\") }, { listOf(\"arr_delay\", \"dep_delay\") })\n.summarize(\n\"mean_arr_delay\" `=` { it[\"arr_delay\"].mean(removeNA = true) },\n\"mean_dep_delay\" to  { it[\"dep_delay\"].mean(removeNA = true) }\n)\n.filter { (it[\"mean_arr_delay\"] gt  30)  OR  (it[\"mean_dep_delay\"] gt  30) }\n.sortedBy(\"mean_arr_delay\")\n</code></pre> <pre><code>year   month   day       mean_arr_delay       mean_dep_delay\n2013      10    11              18.9229              31.2318\n2013       5    24              24.2574              30.3407\n2013       6     2               26.075              34.0133\n2013       6    26              27.3174             30.61175\n2013       6    10              28.0222             30.61945\n2013       7     8              29.6488              37.2966\n2013       8    22              29.9767              33.6004\n2013       2    27               31.252              37.7632\n</code></pre> <p>Note</p> <p>Both  <code>=</code> and <code>to</code> are supported in table expressions.</p>"},{"location":"data_manip/#summarize-data-with-summarize","title":"Summarize Data with <code>summarize</code>","text":""},{"location":"data_manip/#examples","title":"Examples","text":"<ol> <li>Add a suffix to some column names <pre><code>// first select column names to be altered\nirisData.names.filter { it.startsWith(\"Sepal\") }.map {\n// second, apply renaming\noldName -&gt; irisData.rename(oldName to (\"My\" + oldName)) }\n</code></pre></li> </ol>"},{"location":"data_model/","title":"Data model of <code>krangl</code>","text":"<p>What is a DataFrame?</p> <p>A \"tabular\" data structure representing cases/records (rows), each of which consists of a number of observations or measurements (columns) reference</p> <p>And by mapping this defintion to Kotlin code, we obtain the core abstraction of <code>krangl</code>: <pre><code>interface DataFrame {\nval cols: List&lt;DataCol&gt;\n}\n\nabstract class DataCol(val name: String) {\nabstract fun values(): Array&lt;*&gt;\n}\n</code></pre> * Implemented as column model to allow for vectorization where possible * Column implementations using nullable types <code>String?</code>, <code>Int?</code>, <code>Double?</code>, <code>Boolean?</code> and <code>Any?</code> * Internal length and type consistency checks (e.g. prevent duplicated column names)</p>"},{"location":"data_model/#to-type-or-not-to-type","title":"To type or not to type?","text":"<ul> <li>Static types are cool, but most data has no type</li> <li>It's more robust/fun to use types and they allow for better design</li> <li>Many data attributes are very fluent</li> </ul> <p><pre><code>data class Employee(val id:Int, val name:String) val staffStats = listOf(Employee(1, \"John\"), Employee(2, \"Anna\"))  .predictNumSickDays()     // new type!\n.addPerformanceMetrics()  // new type!\n.addSalaries()            // new type!\n.correlationAnalysis()    // odd generic signature :-|\n</code></pre> * R/python lack static typing, which make such workflows more fluent/fun to write</p> <pre><code>staff %&gt;% mutate(sick_days=predictSickDays(name)) %&gt;%   # table with another column\nleft_join(userPerf) %&gt;%                       # and some more columns\nleft_join(salaries) %&gt;%                       # and even more columns\nselect_if(is.numeric) %&gt;%                     correlate(type=\"spearman\")                    # correlate numeric attributes\n</code></pre> <p>Defining types is a tedious process.</p> <p><code>krangl</code> allows to mix typed and untyped data in a tablular data structure:</p> <p><code>val dataFrame : DataFrame =</code></p> <code>employee:Employee</code> <code>sales:List&lt;Sale&gt;</code> <code>age:Int</code> <code>address:String</code> <code>salary:Double</code> <code>Employee(23, \"Max\")</code> <code>listOf(Sale(...), Sale())</code> 23 \"Frankfurt\" 50.3E3 ... ... ... ... ... <p>It implements a  <code>pandas</code>/<code>tidyverse</code> like API to create, manipulate, reshape, combine and summarize  data frames</p> <pre><code>// aggregations like\ndataFrame.groupBy(\"age\").count()\ndataFrame.summarize(\"mean_salary\"){ mean(it[\"salaray\"])}\n\n// integration like\nval df: DataFrame = dataFrame.leftJoin(otherDF)\n\n// transformations like\ndataFrame.addColumn(\"intial\"){ it[\"employee\"].map&lt;Employee&gt;{ it.name.first() }}\n</code></pre>"},{"location":"data_model/#get-your-data-into-krangl","title":"Get your data into krangl","text":"<p>It allows to read from tsv, csv, json, jdbc, e.g.</p> <pre><code>val users = dataFrameOf(\n\"firstName\", \"lastName\", \"age\", \"hasSudo\")(\nnull , \"meyer\" , 23, null)\n\nval tornados = DataFrame.readCSV(pathAsStringFileOrUrl)\ntornados.writeCSV(File(\"tornados.txt.gz\"))\n</code></pre> <ul> <li>Guess column types &amp; default parameters</li> <li>Built-in missing value support</li> </ul> <p>Convert any iterable into a data-frame via extension function + reflection</p> <pre><code>data class Person(val name:String, val address:String)\nval persons : List&lt;Person&gt; = ...\n\nval personsDF: DataFrame = persons.asDataFrame() </code></pre> <p>When doing so non-basic properties will be preserved as <code>AnyCol</code>. To further destructured these we can use <code>unfold</code>:</p> <p><pre><code>data class City(val name:String, val code:Int)\ndata class Person(val name:String, val address:City)\n\nval persons : List&lt;Person&gt; = listOf(\nPerson(\"Max\", City(\"Dresden\", 12309)),\nPerson(\"Anna\", City(\"Berlin\", 10115))\n)\n\nval personsDF: DataFrame = persons.asDataFrame()\npersonsDF.unfold&lt;City&gt;(\"address\") </code></pre> Both the column and the type are provided. </p>"},{"location":"faq/","title":"F.A.Q","text":""},{"location":"faq/#how-to-rewrite-common-sql-bits-with-krangl","title":"How to rewrite common SQL bits with <code>krangl</code>?","text":"<ol> <li><code>select this, that from there where that &gt;5</code></li> </ol> <pre><code>there.select(\"this\", \"that\").filter{ it[\"that\"] gt 5 }\n</code></pre>"},{"location":"faq/#why-doesnt-krangl-provide-vectorized-comparison-operators","title":"Why doesn't krangl provide vectorized comparison operators?","text":"<p>Some (<code>+</code>, <code>-</code>, <code>*</code>, <code>!</code>) can be overridden for collections, but others cannot (e.g. all arithmetic and boolean comparison ops)</p> <p>No vectorization for <code>&gt;</code>,  <code>&amp;&amp;</code> <code>==</code>, etc. in table forumlas \u2192 Use function calls or not so pretty <code>gt</code>, <code>AND</code>, <code>eq</code>, etc.</p>"},{"location":"faq/#can-we-build-data-science-workflows-with-kotlin","title":"Can we build data science workflows with Kotlin?","text":"<p>First, should we? Yes, because</p> <ul> <li>R &amp; Python fail to be scalable &amp; robust solutions for data science</li> <li>Java is known for great dependency tooling &amp; scalability</li> <li>Java as a language is less well suited for data-science (cluttered, legacy bits)</li> </ul> <p>In Febuary 2018 Kotlin v1.0 was released. Designed with DSLs in mind it comes alongs With great features language such Type Inference, Extension Functions, Data Classes, or Default Parameters, making it a perfect choice to do data science on the JVM.</p>"},{"location":"faq/#how-does-krangl-compare-to-what-rdplyr-or-pythonpandas","title":"How does <code>krangl</code> compare to what R/dplyr or python/pandas?","text":"<pre><code>flights\n.groupBy(\"year\", \"month\", \"day\")\n.select({ range(\"year\", \"day\") }, { listOf(\"arr_delay\", \"dep_delay\") })\n.summarize(\n\"mean_arr_delay\" to { it[\"arr_delay\"].mean(removeNA = true) },\n\"mean_dep_delay\" to { it[\"dep_delay\"].mean(removeNA = true) }\n)\n.filter { (it[\"mean_arr_delay\"] gt  30)  OR  (it[\"mean_dep_delay\"] gt  30) }\n</code></pre> <p>And the same snippet written in <code>dplyr</code>:</p> <pre><code>flights %&gt;%\ngroup_by(year, month, day) %&gt;%\nselect(year:day, arr_delay, dep_delay) %&gt;%\nsummarise(\nmean_arr_delay = mean(arr_delay, na.rm = TRUE),\nmean_dep_delay = mean(dep_delay, na.rm = TRUE)\n) %&gt;%\nfilter(mean_arr_delay &gt; 30 | mean_dep_delay &gt; 30)\n</code></pre> <p>The biggest different are the comparison operators, which Kotlin does not allow to be overridden in a vectorized way.</p> <p>And the same in <code>pandas</code>. {no clue, PR needed here!}</p>"},{"location":"faq/#how-to-add-columns-totals-to-data-frame","title":"How to add columns totals to data-frame?","text":"<pre><code>val foo = dataFrameOf(\n\"Name\", \"Duration\", \"Color\")(\n\"Foo\", 100, \"Blue\",\n\"Goo\", 200, \"Red\",\n\"Bar\", 300, \"Yellow\")\n\nval columnTotals = foo.cols.map {\nit.name to when (it) {\nis IntCol -&gt; it.sum()\nelse -&gt; null // ignored column types\n}\n}.toMap().run {\ndataFrameOf(keys)(values)\n}\n\n\nbindRows(foo, columnTotals).print()\n</code></pre>"},{"location":"faq/#how-to-add-a-column-at-a-certain-index-position","title":"How to add a column at a certain index position?","text":"<pre><code>fun DataFrame.addColumnAtIndex(columnName: String, index: Int, expression: TableExpression): DataFrame {\nreturn addColumn(columnName) { expression(ec, ec) }\n.select(names.take(index) + listOf(columnName) + names.takeLast(index))\n}\n\nirisData.addColumnAtIndex(\"foo\", 1) { \"krangl rocks!\" }.print()\n</code></pre>"},{"location":"faq/#further-reading","title":"Further Reading?","text":"<p>For a first primer see KotlinConf 2019 slides about Data Science with kotlin</p> <ul> <li> <p><code>krangl</code> presentation at Kotlin-Night in Frankfurt (March 2018)</p> </li> <li> <p>Krangl Introduction A presentation from June 2016 (sources)</p> </li> </ul>"},{"location":"reshape/","title":"Reshaping Data","text":"<p>Note</p> <p>For a primer on tidy data read http://garrettgman.github.io/tidying/</p> <p>{% endhint %}</p>"},{"location":"reshape/#example-data-reshaping-with-krangl","title":"Example: Data Reshaping with <code>krangl</code>","text":"<pre><code>val climate = dataFrameOf(\n\"city\", \"coast_distance\", \"1995\", \"2000\", \"2005\")(\n\"Dresden\", 400, 343, 252, 423,\n\"Frankfurt\", 534, 534, 435, 913)\n</code></pre> <pre><code>     city   coast_distance   1995   2000   2005\n  Dresden              400    343    252    423\nFrankfurt              534    534    435    913\n</code></pre> <pre><code>climate. gather(\"year\", \"rainfall\", columns = { matches(\"[0-9]*\")} )\n</code></pre> <pre><code>     city   coast_distance   year   rainfall\n  Dresden              400   1995        343\nFrankfurt              534   1995        534\n  Dresden              400   2000        252\nFrankfurt              534   2000        435\n  Dresden              400   2005        423\nFrankfurt              534   2005        913\n</code></pre> <p>???</p> <p><code>colummns</code> use function literals again, with column names type as receiver</p>"},{"location":"reshape/#example-data-ingestion-with-krangl","title":"Example: Data Ingestion with <code>krangl</code>","text":"<pre><code>dataFrameOf(\"user\")(\"brandl,holger,37\")\n.apply { print() }\n.separate(\"user\", listOf(\"last_name\", \"first_name\",\"age\"), convert = true)\n.apply { print() }\n.apply { glimpse() }\n</code></pre> <pre><code>user\nbrandl,holger,37\n</code></pre> <pre><code>last_name   first_name   age\n   brandl       holger    37\n</code></pre> <pre><code>DataFrame with 1 observations\nlast_name  : [Str]  , [brandl]\nfirst_name : [Str]  , [holger]\nage        : [Int]  , [37]\n</code></pre>"},{"location":"reshape/#digest-objects-into-attribute-columns","title":"Digest objects into attribute columns","text":"<p>Cherry-pick properties with <code>Iterable&lt;T&gt;.deparseRecords</code> <pre><code>val deparsedDF = records.deparseRecords { mapOf(\n\"age\" to it.age, \"weight\" to it.mean_weight\n) }\n</code></pre></p> <p>Be lazy and use reflection <pre><code>data class Person(val name:String, val age:Int)\nval persons :List&lt;Person&gt; = listOf(Person(\"Max\", 23), Person(\"Anna\", 43))\n\nval personsDF: DataFrame = persons.asDataFrame() personsDF\n</code></pre></p> <pre><code>age   name\n 23   Max\n 43   Anna\n</code></pre>"},{"location":"reshape/#listobject-columns","title":"List/object columns","text":"<p><code>krangl</code> supports arbitrary types per column</p> <pre><code>val persons: DataFrame = dataFrameOf(\"person\")(persons) persons\n</code></pre> <pre><code>                      person\n   Person(name=Max, age=23)\n   Person(name=Anna, age=43)\n</code></pre> <pre><code>personsDF2.glimpse()\n</code></pre> <pre><code>DataFrame with 2 observations\nperson  : [Any] , [Person(name=Max, age=23), Person(name=Anna, age=43)]\n</code></pre>"},{"location":"reshape/#unfold-objects-into-columns","title":"Unfold objects into columns","text":"<ul> <li>similar to <code>separate()</code> but for object columns</li> </ul> <p><pre><code>data class Person(val name:String, val age:Int)\nval persons :Iterable&lt;Person&gt; = listOf(Person(\"Max\", 22), Person(\"Anna\", 23))\n\nval df : DataFrame = dataFrameOf(\"person\")(persons)\n\ndf.names\n</code></pre> <pre><code>[\"person\"]\n</code></pre> --</p> <p>Expand properties of <code>person</code> into columns via reflection</p> <pre><code>var personsDF = df.\nunfold&lt;Person&gt;(\"person\", keep=true) // unfold&lt;Person&gt;(\"person\", select=listOf(\"age\"))\n\npersonsDF.names   </code></pre> <pre><code>[\"person\", \"name\", \"age\"]\n</code></pre>"},{"location":"reshape/#let-krangl-define-the-schema","title":"Let krangl define the schema","text":"<p>Infer a schema with</p> <p><pre><code>irisData.printDataClassSchema(\"Iris\")\n</code></pre> which makes krangl to print the Kotlin data class schema for data frame:</p> <pre><code>data class Iris(val sepalLength: Double, val sepalWidth: Double, val petalLength: Double, val petalWidth: Double, val species: String)\n\nval records: Iterable&lt;Iris&gt; = irisData.rowsAs&lt;Iris&gt;()\n</code></pre> <p>Paste it back into workflow code and continue with typed objects!</p> <pre><code>records.take(1)\n</code></pre> <pre><code>[ Iris(sepalLength=5.1, sepalWidth=3.5, petalLength=1.4, petalWidth=0.2, species=setosa) ]\n</code></pre>"},{"location":"time-series/","title":"Time Series","text":"<p>Those who have knowledge, don't predict. Those who predict, don't have   knowledge. - Lao Tzu</p>"},{"location":"time-series/#basics","title":"Basics","text":"<p>Analyzing time series works like a breeze with <code>krangl</code>. Conceptually, time-series are simply tables with a <code>java.util.Date</code> column. They can be analyzed by means of grouping and aggregation as any other data frame.</p> <pre><code>\n</code></pre> <p>{todo} file a ticket if you find this interesting :-)</p>"},{"location":"tutorials/data_vis/","title":"How to visualize tabular data when using krangl?","text":"<p>There are multiple visualization engines that are compatible with <code>krangl</code>.</p>"},{"location":"tutorials/data_vis/#lets-plot","title":"lets-plot","text":"<p><code>lets-plot</code> is an open-source plotting library for statistical data which is written entirely in the Kotlin programming language. </p> <p>For new users of krangl, we strongly recommend to use <code>lets-plot</code> because of its stability and ease of use.</p> <p>For a fully worked out tutorial see the jupyter workbook sleep_patterns.ipynb.</p> <p>Example</p> <pre><code>import jetbrains.letsPlot.*\n\nirisData.letsPlot{ x= \"Sepal.Width\"; y=\"Sepal.Length\"; color=\"Species\"}\n+ geomPoint()\n</code></pre> <p></p>"},{"location":"tutorials/data_vis/#kravis","title":"kravis","text":"<p><code>kravis</code> Implements a grammar to create a wide range of plots using a standardized set of verbs.</p> <p><code>kravis</code> essentially wrap <code>ggplot2</code> from R. The latter it will access via different backends like a local installation, docker or Rserve. It is more versatile compared to <code>lets-plots</code> because it supports to full ggplot2 grammar, but relies on R as non-java binary as dependency.</p> <p>Example</p> <pre><code>import kravis.* import krangl.irisData irisData.ggplot(\"Species\" to x, \"Petal.Length\" to y)\n.geomBoxplot()\n.geomPoint(position = PositionJitter(width = 0.1), alpha = 0.3)\n.title(\"Petal Length by Species\")\n</code></pre> <p></p>"},{"location":"tutorials/data_vis/#other-options","title":"Other options","text":"<p>There are great other libaries available, which typically don't work with <code>krangl</code> yet, but provide awesome ways to visualize data. See here for a listing.</p>"},{"location":"tutorials/machine_learning/","title":"Machine Learning","text":"<p><code>krangl</code> integrates nicely with existing JVM machine learning libraries.</p>"},{"location":"tutorials/machine_learning/#machine-learning-with-smile","title":"Machine Learning with SMILE","text":"<p>The  https://github.com/haifengl/smile projects contains tons of implementations needed for modern data science. Among others</p> <ul> <li> <p>Classification Support Vector Machines, Decision Trees, AdaBoost, Gradient Boosting, Random Forest, Logistic Regression, Neural Networks, RBF Networks, Maximum Entropy Classifier, KNN, Na\u00efve Bayesian, Fisher/Linear/Quadratic/Regularized Discriminant Analysis.</p> </li> <li> <p>Regression Support Vector Regression, Gaussian Process, Regression Trees, Gradient Boosting, Random Forest, RBF Networks, OLS, LASSO, Ridge Regression.</p> </li> <li> <p>Feature Selection Genetic Algorithm based Feature Selection, Ensemble Learning based Feature Selection, Signal Noise ratio, Sum Squares ratio.</p> </li> <li> <p>Clustering BIRCH, CLARANS, DBScan, DENCLUE, Deterministic Annealing, K-Means, X-Means, G-Means, Neural Gas, Growing Neural Gas, Hierarchical Clustering, Sequential Information Bottleneck, Self-Organizing Maps, Spectral Clustering, Minimum Entropy Clustering.</p> </li> <li> <p>Manifold learning IsoMap, LLE, Laplacian Eigenmap, t-SNE, PCA, Kernel PCA, Probabilistic PCA, GHA, Random Projection, MDS</p> </li> <li> <p>Nearest Neighbor Search BK-Tree, Cover Tree, KD-Tree, LSH.</p> </li> <li> <p>Sequence Learning Hidden Markov Model, Conditional Random Field.</p> </li> <li> <p>Natural Language Processing Tokenizer, Keyword Extractor, Stemmer, POS Tagging, Relevance Ranking</p> </li> </ul>"},{"location":"tutorials/machine_learning/#example","title":"Example","text":"<p>It's easy to use <code>krangl</code> and <code>smile</code> to build data science workflows. Here is an example for doing a PCA.</p> <pre><code>val irisArray = irisData.remove(\"Species\").toArray()\n\n//barchart\npca.varianceProportion.withIndex().plot({ it.index }, { it.value }).geomCol().show()\n\nval projection = pca.setProjection(2).projection\n\n// merge back in the group labels to color scatter\nvar pc12 = projection.transpose().array().withIndex().deparseRecords {\nmapOf(\n\"index\" to it.index + 1,\n\"x\" to it.value[0],\n\"y\" to it.value[1])\n}\n\npc12 = pc12.leftJoin(irisData.addColumn(\"index\") { rowNumber })\n\npc12.plot(x=\"x\", y = \"y\", color = \"Species\").geomPoint().show()\n</code></pre>"},{"location":"tutorials/report_rendering/","title":"Report Rendering","text":"<p>Data science workflows written with Kotlin can be rendered to html, pdf, and markdown using Jupyter. To do so we need a kernel.</p> <p>A kernel provides programming language support in Jupyter. IPython is the default kernel. Additional kernels include R, Julia, and many more.</p> <p>Two competing kernels are available for Kotlin</p> <ol> <li> <p>https://github.com/ligee/kotlin-jupyter</p> <ul> <li>More established</li> <li>Backed by JB</li> <li>Friendly and responsive developers</li> <li>Not really active</li> </ul> </li> <li> <p>https://github.com/twosigma/beakerx</p> <p>a collection of JVM kernels and interactive widgets for plotting, tables, auto-translation, and other extensions to Jupyter Notebook.</p> <ul> <li>Very active, fast progress</li> <li>Friendly and very responsive developers</li> <li>Not just a kernel</li> <li>Display handler registry in kernel <code>krangl.beakerx.TableDisplayer.register()</code></li> </ul> </li> </ol> <p>In our opinion, Kotlin-powered Jupyter notebooks are definitely cool, but lacks efficiency because of missing tooling (error checking, completion, refactoring):</p>"},{"location":"tutorials/report_rendering/#build-reports-embedding-code-and-results","title":"Build reports embedding code and results","text":"<p>However, the kernel can be used for literate programming, which enables result consistency and streamline communication by building reports from code</p> <p>So finally we want to develop data workflows interactively using plain and simple code. Similar to how it is possible with R via the well known tool chain built around <code>knitr</code>-&gt;<code>pandoc</code>: </p> <p>Similary, in python this can be achieved by startin with markdown -&gt; <code>notedown</code> + <code>nbconvert</code></p> <p>Can we do this with Kotlin?</p> <p>Let's consider the following example</p> <pre><code>//' ## Flowers Analysis\n\n//' The iris flower\n//' ![](https://goo.gl/tTbZMq)\n//@file:MavenRepository(\"bintray-plugins\",\"http://jcenter.bintray.com\")\n\n@file:DependsOnMaven(\"com.github.holgerbrandl.krangl:krangl:0.15.6\")\n\nimport krangl.*\n\n\n\n//' The first records in the input data (which is bundled with krangl) are\nirisData\n\n//' The structure of the input data is\nirisData.glimpse()\n\n//' Calculate mean petal\nval summarizeDf: DataFrame = irisData\n.groupBy(\"Species\")\n.summarize(\"mean_petal_width\") { it[\"Petal.Width\"].mean() }\n\n//' Print the summarized data\nsummarizeDf.print()\n\n//' Conclusion: Iris flowers of species _virginica_ have on average the largest petal width.\n</code></pre> <p>An <code>kts-&gt;html</code> conversion could be impelmented as follows:</p> <pre><code>inputScript=krangl_example_report.kts\nreportName=$(basename $inputScript .kts)\n\n# https://www.r-project.org/\nRscript - ${inputScript} &lt;&lt;\"EOF\"\nknitr::spin(commandArgs(T)[1], doc = \"^//'[ ]?\", knit=F)\nEOF\n\n# https://github.com/holgerbrandl/kscript\nkscript -t 'lines.map { it.replace(\"{r }\", \"\")}.print()' ${reportName}.Rmd &gt; ${reportName}.md\n\n# https://github.com/aaren/notedown\nnotedown ${reportName}.md &gt; ${reportName}.ipynb\n\n# http://jupyter.org/install\njupyter nbconvert --ExecutePreprocessor.kernel_name=kotlin \\\n--execute --to html ${reportName}.ipynb --output ${reportName}\n</code></pre> <p>Proof-of-Concept. :-)</p> <p></p>"},{"location":"tutorials/statistics/","title":"Regression Analysis","text":"<p>Using libaries http://commons.apache.org/proper/commons-math/ and https://github.com/chen0040/java-glm, krangl allows to perform R-like regression analyses.</p> <p>Example: How to fit a linear regression model per group?</p> <p><pre><code>val irisModel = irisData\n.groupBy(\"Species\")\n.summarize(\"lm\") {\nval x = it[\"Sepal.Length\"].asDoubles().filterNotNull().toDoubleArray()\nval y = it[\"Sepal.Width\"].asDoubles().filterNotNull().toDoubleArray()\n\nval xTransposed = MatrixUtils.createRealMatrix(arrayOf(x)).transpose().data\nSimpleRegression().apply { addObservations(xTransposed, y) }\n}\n.unfold&lt;SimpleRegression&gt;(\"lm\", properties = listOf(\"intercept\", \"slope\"))\n</code></pre> <pre><code>   Species                                                                   lm       slope   intercept\n    setosa   org.apache.commons.math3.stat.regression.SimpleRegression@66133adc       0.798     -0.5694\nversicolor   org.apache.commons.math3.stat.regression.SimpleRegression@7bfcd12c       0.319      0.8721\n virginica   org.apache.commons.math3.stat.regression.SimpleRegression@42f30e0a       0.2318      1.446\n</code></pre></p>"}]}